{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>\u4e2d\u6587\u6587\u6863</p>"},{"location":"#bioxel-nodes","title":"Bioxel Nodes","text":"<p>Bioxel Nodes is a Blender addon for scientific volumetric data visualization. It using Blender's powerful Geometry Nodes and Cycles to process and render volumetric data.</p> <p></p> <ul> <li>Realistic rendering result, also support EEVEE NEXT.</li> <li>Support multiple formats.</li> <li>Support 4D volumetric data.</li> <li>All kinds of cutters.</li> <li>Simple and powerful nodes.</li> <li>Based on blender natively, can work without addon.</li> </ul> <p>Read the getting started to begin your journey into visualizing volumetric data!</p> <p>Welcome to our discord server, if you have any problems with this add-on.</p>"},{"location":"#support-multiple-formats","title":"Support Multiple Formats","text":"Format EXT DICOM .dcm, .DCM, .DICOM, .ima, .IMA BMP .bmp, .BMP JPEG .jpg, .JPG, .jpeg, .JPEG PNG .png, .PNG TIFF .tif, .TIF, .tiff, .TIFF Nifti .nia, .nii, .nii.gz, .hdr, .img, .img.gz Nrrd .nrrd, .nhdr HDF5 .hdf, .h4, .hdf4, .he2, .h5, .hdf5, .he5 OME .ome.tiff, .ome.tif MRC .mrc, .mrc.gz, .map, .map.gz"},{"location":"#support-4d-volumetric-data","title":"Support 4D volumetric data","text":"<p>\ud83e\udd70 4D volumetric data can also be imported into Blender.</p>"},{"location":"#support-eevee-next","title":"Support EEVEE NEXT","text":"<p>\ud83d\udc4d EEVEE NEXT is absolutely AWESOME! Bioxel Nodes is fully support EEVEE NEXT now! However, there are some limitations:</p> <ol> <li>Only one cutter supported.</li> <li>EEVEE result is not that great as Cycles does.</li> </ol>"},{"location":"#known-limitations","title":"Known Limitations","text":"<ul> <li>Only works with Cycles CPU , Cycles GPU (OptiX), EEVEE</li> <li>Section surface cannot be generated when convert to mesh (will be supported soon)</li> </ul>"},{"location":"#roadmap","title":"Roadmap","text":"<ul> <li>Better multi-format import experience</li> <li>One-click bake model with texture</li> <li>AI Segmentation to Generate Labels</li> </ul>"},{"location":"SARS-Cov-2/","title":"SARS-Cov-2","text":"<p>In this tutorial, we'll make a structural visualzation of the SARS-Cov-2 Virus. Please see step by step to make sure you have a basic understanding of how to use the addon, and make sure the addon version is v1.0.2 or higher!</p> <p>Research data is from paper published in September 2020 in Cell Press (https://www.cell.com/cell/fulltext/S0092-8674(20)31159-4) by Li Sai team at Tsinghua University. This research revealed the molecular assembly of the authentic SARS-CoV-2 virus using cryoelectron tomography (cryo-ET) and subtomogram averaging (STA). Here is an official video of this study</p> <p>\"It remains enigmatic how coronaviruses pack the \u223c30-kb RNA into the \u223c80-nm-diameter viral lumen. Are the RNPs ordered relative to each other to avoid RNA entangling, knotting, or even damage or are they involved in virus assembly?\" Three assembly classes were proposed in the paper, we will make a visualzation of the \"eggs-in-a-nest\"-shaped RNPs assembly, based on real cryo-ET data.</p>"},{"location":"SARS-Cov-2/#download-and-import-data","title":"Download and import data","text":"<p>The data of this research is hosted on EMDB (https://www.ebi.ac.uk/emdb), and the website of SARS-Cov-2 virus is here. Open the page, find \"Download\" button and select the first selection \"3D Volume (.map.gz)\".</p> <p>In case you can't download data, you can download here.</p> <p>SARS-Cov-2.map</p> <p>After downloading, put it into any directory and import the data. In the import options, it is recommended to adjust the Bioxel Size to 5, in order to reduce the shape of the data to increase the speed of calculation and rendering. If you are confident in the performance of your hardware, you can leave the original 2.72 unchanged. After adjusting the Bioxel Size, the shape of the converted data will be calculated below based on the current bioxel size. The amount of data will increase exponentially with larger shape, and may result in OOM (out of memory).</p>"},{"location":"SARS-Cov-2/#cutout-the-virus","title":"Cutout the Virus","text":"<p>After importing, you can get the virus by creating and connecting nodes and setting parameters as shown below</p> <p></p> <p>Place the light and the camera in the way as below. The backlight is a area light, color white, intensity 500W, spread 90\u00b0, and inside the virus, place a point light, color <code>FFD08D</code>, intensity 5W. Camera focal length is 200 mm. the background color is pure black. The Look of the color management is High Contrast.</p> <p></p> <p>Continue editing the node, followed by \"Set Properies\" and \"Set Color by Ramp 4\" node, the parameters of these two nodes are set as shown in the figure, where the color part, from top to bottom, is set to <code>E1D0FC</code> (1.0), <code>FFE42D</code> (0.5), <code>3793FF</code> (0.5), <code>FFFF8EC</code> (0.1) (alpha value in parentheses). Color alpha also affects density.</p> <p></p> <p>If you feel that rendering is too slow, see here for suggestions</p>"},{"location":"SARS-Cov-2/#color-the-rnps-alone","title":"Color the RNPs alone","text":"<p>The current rendering is pretty good, but considering that my goal is to make it clear how the RNPs are arranged within the virus, the RNPs should be colored differently than the others. So how to color the RNPs alone?</p> <p>First of all, we have to separate the RNPs. The value of RNPs is between the membrane and S protein, so it is very difficult to separate. The good thing is that the virus is spherical, we can separate the RNPs part of the virus from the rest by using a sphere cutter. To do so, in the Geometry Nodes panel menu of the container, click Bioxel Nodes &gt; Add a Cutter &gt; Sphere Cutter, and adjust the scale and position of the newly created sphere object named \"Sphere_Cutter\" appropriately, so that it can just separate the internal RNPs and membrane of the virus.</p> <p></p> <p>The process of changing the position of the \"Sphere_Cutter\" object can be very laggy, then you can turn off \"With Surface\" and do it in Slice Viewer mode. Once you are happy with it, you can restore the settings.</p> <p>Then we turn on Invert in the \"Sphere Cutter\" node and you can see the opposite result. This way we've managed to separate the two, next let's color them separately and finally merge them with Join Component. Create and join the nodes as shown below, where the second Cutter node is copied and the color value in Set Color is <code>FFDDFE</code> (0.5). If all is well, the rendering should look like below.</p> <p></p> <p>At this point, the rendering of a SARS-Cov-2 virus is complete!</p>"},{"location":"SARS-Cov-2/#render-rnps-and-membranes","title":"Render RNPs and Membranes","text":"<p>Realistic rendering is great, but Non-photorealistic rendering (NPR) is better for presenting structural information. So I will render ultrastructure of the RNPs assembly with toon shader.</p> <p></p> <p>The silhouettes of RNPs uses Blender's Line Art feature, but Line Art must be based on a mesh. Select the nodes that are extruding the RNPs (i.e., the \"Cut\" nodes that are in charge of cutting out the RNPs), and right-click, click Bioxel Nodes &gt; Extract Mesh. This gives you a new mesh object of the RNPs.</p> <p>Extract the membrane mesh in the same way.</p> <p>The membrane has a much higher value than the rest of the virus, so let's create a new \"Cutout\" node, also after the ReCenter, but with the threshold adjusted to 0.13. After the Cutout, connect to the \"To Surface\" node and parameterize it as shown in the figure, noting that the Remove Island Threshold is set to 1000 so that any fragments smaller than 1000 pts be eliminated. Then select the \"To Surface\" node, and perform the operation of extracting the mesh.</p> <p></p> <p>The mesh of the membrane needs to be cut in half, this can be done with the Box Trim brush in sculpt mode or with the Boolean modifier. the mesh of the RNPs may also need some repair work, I cleaned up some of the broken surfaces of the RNPs. all the meshes are now ready to be used.</p> <p></p> <p>For Line Art, please see the video tutorial from Blender Secrets.</p> <p>Finally, an infographic on the ultrastructure of RNPs is done!</p> <p></p> <p>If you have trouble following the docs, you can download the project files.</p> <p>SARS-Cov-2.zip</p>"},{"location":"SARS-Cov-2/#homework","title":"Homework","text":"<p>Other data relevant to the study are provided in the paper, you could try visualizing them.</p> <p></p> <p>Go to the official EMDB website https://www.ebi.ac.uk/emdb/ and enter the EMD number in the search box to get them.</p> <p>The Electron Microscopy Data Bank (EMDB) is a public repository for cryogenic-sample Electron Microscopy (cryoEM) volumes and representative tomograms of macromolecular complexes and subcellular structures. If you want to get data on other virus, just enter their name in the search box. For example, hepatitis B virus, enter it into the search box, then select Virus in the Sample Type on the left side, and download the data you need (it is better to find the corresponding paper to clarify the data information).</p> <p>Try to visualize hepatitis B virus.</p> <p></p>"},{"location":"advanced_usage/","title":"Advanced Usage","text":""},{"location":"advanced_usage/#concepts","title":"Concepts","text":"<p>In the previous section, I mentioned some key concepts, I'll describe them in detail so that you can better understand the following operations.</p>"},{"location":"advanced_usage/#container","title":"Container","text":"<p>First is the Container, it is the easiest to describe, you can think of it as a scene, or a solver container. it is the stage that carries all stuffs.</p>"},{"location":"advanced_usage/#layer","title":"Layer","text":"<p>Second is the Layer, which represents different fields of data under the same location in container of the same subject. Just as view layers in any map app, one as roads, one as satellite view, while in Bioxel, one as MRI, one as CT, one as electrical signals, etc. Some layers are for material, such as color, density, etc., we call them Material Layer. One container contains different layers of one subject each. Any external data imported into the container is converted into the layer.</p>"},{"location":"advanced_usage/#component","title":"Component","text":"<p>Finally, the Component, which is a fragment of Material Layer. Multiple materials (Matters) may exist within the same area with different meanings of presentation, like objects in blender, each representing a part of the scene. Bioxel Nodes provides a series of nodes and tools that allow the user to create material layers (Components) based on the other layers (serve as source data), In the previous section, we used the CT data (layer) to make the material (matter) of skull, this process known as materialization.</p>"},{"location":"advanced_usage/#attache-the-muscles-to-the-skull","title":"Attache the Muscles to the Skull","text":"<p>Multiple components can exist in one container, just as multiple objects can exist in one scene. They can be controlled individually or combined with each other to build complex scenes. Next, let's try cutouting muscle from the VHP anatomical images and attaching the muscles to the skull that created in the previous section. The anatomical images are very large, so I've cropped and scaled them down to 1/4 of their original size for ease of use. Download the file and unzip it into a new directory.</p> <p>VHP_M_AnatomicalImages_Head.zip</p> <p>You can also download the data directly from the official website, https://data.lhncbc.nlm.nih.gov/public/Visible-Human/Male-Images/PNG_format/head/index.html</p> <p>First import the CT data as described in step by step. Then import the anatomical images, but unlike before, this time from the Geometry Nodes menu of the existing container (not the top menu), click Bioxel Nodes &gt; Import Volumetric Data (Init) &gt; as Color, locate to the unzipped folder, and select any .png file (do not multi-select, and do not select the folder). This way the imported layer will be in the same container as the previous CT data. You can also import by dragging it into the container geometry node interface instead of the 3D Viewport interface. Also note that as Color (not as Scalar) is clicked because the anatomical images are RGB data.</p> <p></p> <p>Let's take more time in the import options this time \ud83e\udee1, first let's talk about what the Original Spacing is in the options, you can simply think of it as the original \"pixel size\" of a image, since the volume is 3D, its pixels (i.e., voxels) are cuboids with a length, width, and height rather than 2D rectangles. And their length, width, and height size is the Spacing.</p> <p>Normally, Bioxel Nodes can read the spacing from the data header, and you don't need to fill in the value, but there is no record of that in any PNG image, so you need to input it manually. in the official description of the VHP, it is mentioned that each pixel of the anatomical images corresponds to the size of .33mm, and the thickness of each slice is 1mm, so the Original Spacing of the anatomical images should be set to <code>(0.33, 0.33, 1)</code>.</p> <p>However, the file I provided is scaled by 1/4 for each image, so the X and Y axes need to be multiplied by 4. So the final Original Spacing should be set to <code>(1.33, 1.33, 1)</code>, which should be understandable, right? (If you are importing an official file, then it should still be set to <code>(0.33, 0.33, 1)</code>) Layer Name should be set to \"Anatomical Images\", other options remain default, click Ok.</p> <p></p> <p>After importing, connect the \"Cutout by Hue\" node (Add &gt; Bioxel Nodes &gt; Component &gt; Cutout by Hue) after the newly created \"Fetch Layer\" node, and turn on the Slice Viewer mode preview, as shown below.</p> <p></p> <p>In addition to spacing, the Dicom file also records the subject's position and orientation, but those information is apparently not recorded in PNG format. This results in a mismatch between the CT data and the anatomical images in position. We need to manually align this two layers: First, set the threshold of the \"Cutout by Threshold\" node to 0.2 so that the full head can be cutouted and displayed. Then add \"ReCenter\" node before \"Cutout by Hue\" node and \"Cutout by Threshold\" node each, then add Locater to the \"anatomical images\" workflow (see step by step for details), and finally add \"Join Component\" node (Add &gt; Bioxel Nodes &gt; Component &gt; Join Component), and connect them as shown below, with the parameters set as shown.</p> <p></p> <p>The \"Join Component\" node allows you to merge two components together. Move and rotate the Locater object so that the two components are exactly the same in position. If you're having trouble matching them up, here's the exact transform values to fill in the Locater object properties.</p> <p></p> <p>Next let's cutout the muscles individually.</p> <p>First let's talk about the \"Cutout by Hue\" node. Literally, it cutout regions by hue of color. If you select this node and press \"M\" key to temporarily mute it, you'll see that the data becomes a cube with blue parts in Slice Viewer mode. the default value of Hue in the \"Cutout by Hue\" node is red, meaning that the node retains areas of the body that are close to red, and strip out the blue, which is on the opposite side of the red in the hue ring, leaving the human body parts.</p> <p>If you turn down the value of Sensitivity, you'll see that the visabile part is decreasing, leaving only the part more closer to red, and the muscle happens to be red, so we can easily cutout the muscle. The color of the specimen tissue is not as vibrant as it is in the live state, and we can fine-tune the color to restore the vibrancy by using the \"Set Color by Color\" node (Add &gt; Bioxel Nodes &gt; Property &gt; Set Color by Color).</p> <p>To finally put it all together, connect and set the nodes as shown below, where the two colors in \"Set Color by Ramp 2\" node are <code>E7D2C5</code> and <code>FFEDEC</code>. If everything is working correctly, you'll get the rendering below.</p> <p></p> <p>You can also add \"Transfrom\" and \"Cutter\" nodes at the end and all components.</p> <p></p> <p>The multimodal data of VHP do not have any deformation or scaling differences, but only positional differences, so all data can be aligned easily. However, in most cases, the differences of different modalities are so great that they need to be registered first, which is not possible with Bioxel Nodes at the moment (but it is in plan). Nevertheless, you can build different components based on the same layer and combine them together. For example, based on the CT data, with the \"Cutout by Range\" node, you can eliminate the low value regions (fat), eliminate the high value regions (bone), and you can still get the muscle. And then attach it to the skull.</p> <p></p> <p>However, the CT values of brain and muscle are very close to each other, so it is extremely difficult to separate the brain from the muscle by threshold. So how should cutout the brain?</p>"},{"location":"advanced_usage/#cutout-the-brain","title":"Cutout the Brain","text":"<p>We can use AI technology to realize the division of brain regions, this process is called Segmentation, and the brain regions are as label. There are many models and methods for medical image segmentation, here we recommend Total Segmentator.</p> <p>It is an out-of-the-box CT/MRI medical image segmentation Python library. You can deploy Total Segmentator locally or process your data through the official online site https://totalsegmentator.com.</p> <p>Let me demonstrate the operation, we are still using the CT data from VHP. Click on \"Drop DICOM.zip or ...\" and select the VHP_M_CT_Head.zip file. Enter \"brain\" below \"Selected task\", press Enter to confirm. Finally click \"Process data\" button.</p> <p></p> <p>Wait for the uploading and processing, after all, you will be redirected to the following page, click \"Download results\" button, download and unzip segmentations.zip to any folder directory.</p> <p></p> <p>In case you can't get the brain segment (label), you can download it directly (without unzipping it).</p> <p>VHP_M_CT_Head_Brain.nii.gz</p> <p>Next we import the brain segment (label) into the container in the same way as we imported the anatomical imagess(under the same container), but this time selecting as Label, with the Layer Name set to \"Brain\", and leaving the other options as default. Once the import is complete, a new \"Fetch Layer\" node will be added. Create and set the node as shown below, and you should be able to see the surface of brain.</p> <p></p> <p>Do you see the \"step\" like shape on surface? this is due to the low precision of the AI segmentation results. So How to addressing the issue? Select the Fetch Layer node of the brain label, right-click to pop up menu, click Bioxel Nodes &gt; Resample Value, in the dialog box, change the \"Smooth Size\" to 3 or higher (the higher it is, the slower the calculation will be), click OK and wait for the calculation to finish. When it is done, a new layer will be added, replace the original one, is it smoother? The following figure lists different levels of smoothing.</p> <p></p> <p>The smoother it is, the more comfortable it looks, but it also means that more details are lost and the calculation is slower.</p> <p>But if you cut the brain, you will find that the cross-section is homogeneous, this is because the label type layer is does not contain any modality data itself. Bioxel Nodes provides a function to fill in any layer values by label, if you set the value below brain tissue in the non-brain region of CT data, then any \"Cutout\" node will only keep the brain region.</p> <p>The operation is like this, select the \"Fetch Layer\" node of the CT data, right-click to pop up the menu, click Bioxel Nodes &gt; Fill Value by Label, in the dialog box, Label is set to the newly imported brain label layer, Fill Value is set to -100 (as long as it is less than the Hu value of the brain tissue), click OK. wait for the data processing, a new data layer will be added to the container when it is finished.</p> <p>As shown in the following figure, connect the nodes and set the node parameters, in which the two colors of \"Set Color by Ramp 2\" node are <code>B26267</code> and <code>EBC5B7</code>, and the \"Cutout by Range\" and \"Set Color by Ramp 2\" node are changed to \"Value\" mode (the default is \"Factor\" mode), because the maximum and minimum values of the brain are too close to each other and difficult to adjust in \"Factor\" mode. To make the brain tissue look more transparent, I add the \"Set Properties\" (Add &gt; Bioxel Nodes &gt; Property &gt; Set Properties) node at the end and changed the \"Density\" to 0.5.</p> <p></p> <p>(Still feel not smooth enough? It's really hard to get rid of \"step\" surface completely at the moment)</p> <p>Now the brain is done. Finally we combine all together and you get something like the following.</p> <p></p> <p>\ud83e\udd17 If you've followed the docs up to this point, give yourself a round of applause, you've mastered this addon! If you have trouble following the docs instruction, you can download the project files to understand how the nodes work.</p> <p>VHP.zip</p> <p>AI segmentation is an essential part of volumetric data visualization. Therefore, the future Bioxel Nodes will integrate some commonly used AI segmentation models, so that users can complete the volumetric data visualization in place!</p>"},{"location":"improve_performance/","title":"Improve Performance","text":"<p>Volume reconstruction and volume rendering are very consuming computation, I believe that this add-on's experience is terrible on poorly hardware. here are tips to improve the add-on performance.</p>"},{"location":"improve_performance/#use-low-res-data-as-preview","title":"Use Low-Res Data as Preview","text":"<p>The addon provides data resample function, the operation is as follows. First, in the container's geometry node, select the layer you need to resample, right-click Bioxel Nodes &gt; Resample Value, in the dialog box, change the \"Bioxel Size\" value to twice or more than the current value, click OK. the addon will create a low-res version of the layer and load it into the container's geometry node.</p> <p></p> <p>You can see that the speed of the reconstruction has been reduced from 240 ms to 37 ms, making it possible to compute in almost real-time, and improving the speed of the feedback of the changing the parameters. Once you are satisfied with the adjustment, you can then connect the original layer to the nodes. This tip can greatly improve the operation experience of the node.</p>"},{"location":"improve_performance/#raise-the-step-rate-of-a-container","title":"Raise the Step Rate of a Container","text":"<p>Step rate is a key setting in volume rendering. The higher the step rate, the faster the rendering will be, but at the same time, the thinner the volume will look. If you want to have a very thin effect, or if you don't need to cut through component, you can always set the step rate high, you can adjust step rate in the render settings globaly. However, I recommend you to adjust the step rate of the container separately, so that it doesn't affect the rendering of the other volume in the Blender file, do as follows.</p> <p>In the container's geometry nodes panel menu, click Bioxel Nodes &gt; Change Container Properties, in the dialog box, raise the \"Step Rate\" value (up to 100) and click OK.</p> <p></p> <p>You can see that the rendering speed is much higher, but at the same time the cuts look blurry and transparent.</p>"},{"location":"improve_performance/#balance-rendering-settings","title":"Balance rendering settings","text":"<p>I list some of the settings that affect the volume rendering most, so you can find the most balanced settings for your needs.</p> <ul> <li> <p>Light Paths &gt; Max Bounces &gt; Volume affects the number of bounces a volume has, the higher the value, the more transparent it will look.</p> </li> <li> <p>Light Paths &gt; Max Bounces &gt; Transparent affects the number of times transparent surfaces are transmitted, the higher the value, the more transparent it will look.</p> </li> <li> <p>Volumes &gt; Step Rate Render | Viewport affects the volume rendering step, the smaller the value, the more detailed the volume will look</p> </li> </ul> <p>Bioxel Nodes provides some render setting presets for quick setup. In the top menu, click Bioxel Nodes &gt; Render Setting Presets, including Performance (left), Balance (center), and Quality (right). Here is a comparison of them.</p> <p></p>"},{"location":"improve_performance/#rendering-with-eevee","title":"Rendering with EEVEE","text":"<p>EEVEE doesn't render volume as well as Cycles, but it does have the advantage of rendering the volumetric data, and is even a better choice if you want to get a clear view of slice. And EEVEE's real-time rendering make it possible to create interactive stuff in Blender.</p>"},{"location":"installation/","title":"Installation","text":"<p>Currently only support Blender 4.2 or above, make sure you have the correct version of Blender.</p>"},{"location":"installation/#install-in-blender-recommended","title":"Install in Blender (recommended)","text":"<p>This is the most recommended way, in the top menu, click Edit &gt; Preferences, in \"Get Extensions\" Section, enter \"bio\" in the search box, then click Install. due to the add-on size (25MB~50MB) you may need to wait a while.</p> <p></p>"},{"location":"installation/#blender-official-extensions-website","title":"Blender Official Extensions Website","text":"<p>Or you can visit the Blender official extensions website at https://extensions.blender.org/add-ons/bioxelnodes/ Click Get Add-on, open Blender, drag in Blender and follow the instructions to install.</p>"},{"location":"installation/#manual-install","title":"Manual Install","text":"<p>You can also install BioxelNodes_{version}.zip manually by downloading from bere. In the top menu, click Edit &gt; Preferences, Add-ons &gt; Install from Disk and select the Zip file you just downloaded.</p>"},{"location":"qa/","title":"Q &amp; A","text":""},{"location":"qa/#nothing-in-the-scene-when-rendering","title":"Nothing in the scene when rendering?","text":"<p>If you're using the Cycles renderer with GPU, make sure your GPU supports \"Optix\", as Bioxel Nodes relies on OSL (Open shader language) for volumetric rendering, otherwise you'll have to use the CPU for rendering.</p> <p>If you're using the EEVEE renderer, this issue is due to EEVEE not loading shaders for some unknown reason, save the file and restart Blender to fix it.</p>"},{"location":"qa/#after-updating-the-addon-the-nodes-in-the-file-have-turned-red","title":"After updating the addon, the nodes in the file have turned red?","text":"<p>This is because the version of the nodes in the file does not match the current version of the addon after updating.</p> <p>If you still want to edit the file with Bioxel Nodes, you can only roll back the addon version to the version that corresponds to the nodes.</p> <p>If you just want the file to work and you won't rely on Bioxel Nodes any more, then you can just click Bioxel Nodes &gt; Relink Node Library &gt; in the top menu and select the corresponding version. Check to see if the nodes are working and rendering properly, and when everything is OK, click Bioxel Nodes &gt; Save Node Library and select the save location in the dialog box.</p>"},{"location":"step_by_step/","title":"Step by Step","text":""},{"location":"step_by_step/#download-data","title":"Download Data","text":"<p>Here is the open data from Visible Human Project (VHP) for you to learn how to use this addon. It is a CT scan image of a male head, download and unzip it to a new directry for later usage.</p> <p>VHP_M_CT_Head.zip</p> <p>VHP original radiology data was shared in the proprietary format that predated DICOM, complicating its use. Now all data has been harmonized to standard DICOM and released in NCI Imaging Data Commons (IDC), you also can download data from IDC by yourself.</p>"},{"location":"step_by_step/#import-data","title":"Import Data","text":"<p>In the top menu, click Bioxel Nodes &gt; Import Volumetric Data (Init) &gt; as Scalar, locate to the unzipped folder, select any DICOM file (don't select more than one, and don't select the folder either), and click Import as Scalar.</p> <p></p> <p>You can also choose to import data by dragging one DICOM file into the 3D viewport (some DICOM files don't have extension suffix and can't be dragged in).</p> <p>The process of reading the data may take a while, the bottom right corner of the Blender interface will show you the progress of the reading, and a dialog box will pop up when the reading is successful. Ignore all the options for now and just click OK, I will explain the purpose of these options later.</p> <p>The import process involves data conversion, so there is more waiting time, and the progress of the import is displayed in the lower right corner of the interface. After importing, the addon will create a new object, with a new geometry nodes that will serve as a \"workbench\" for manipulating the data, the new object is called the Container. The newly imported data is stored in the Container as a Layer, which is loaded into the Container's Geometry node via the \"Fetch Layer\" node (the red one), and be converted into a Component that can be rendered.</p> <p></p> <p>Next, let's preview the data in Blender.</p> <p>In the container's geometry nodes panel menu, click Bioxel Nodes &gt; Add a Slicer. The addon will insert a node named \"Slice\" between the \"Fetch Layer\" and the \"Output\" and create a new plane object named \"Slicer\". Click the \"Slice Viewer\" button in the upper right corner of the 3D viewport to enter the preview mode, then move and rotate the \"Slicer\" object. You will see a slice image of the data, which should be familiar to anyone who has used any DICOM viewing software.</p> <p></p> <p>(If the volume disappears when you click the \"Slice Viewer\" button, save the file and restart Blender, it should be fixed, or you can turn on the Cycles rendering to see the slicer plane as well. The issue is caused by EEVEE's failure of reloading the shaders.)</p> <p>The \"Slicer\" node is used to display the slices of the data, with an external object as the location of the slice plane. This step is not necessary for visualization, but it provides a quick way to preview the data in Blender for user perception. Next, let's turn the volumetric data into a renderable object.</p>"},{"location":"step_by_step/#cutout-the-skull","title":"Cutout the Skull","text":"<p>Bone tends to have much higher CT values than soft tissue, so you can split bone and soft tissue by setting a threshold. In the Geometry Nodes panel menu of the container, click Add &gt; Bioxel Nodes &gt; Component &gt; Cutout by Threshold to add a \"Cutout\" node and connect it between the \"Fetch Layer\" node and the \"Output\", and then set the \"Threshold\" parameter of the \"Cutout by Threshold\" node to 0.3 and turn on the \"With Surface\" option. Switch to viewport shading to \"Render Preview\". The node graph and the render result are shown below.</p> <p></p> <p>If you want the render result to be consistent with the above image, you also need to change the default light object type from \"Point\" to \"Area\" to increase the brightness, and change the Look in Color Management to \"High Contrast\".</p> <p>You can understand the role of the \"Threshold\" parameter in shaping the output by changing it. If you feel very laggy while draging the parameter, you can temporarily turn off the \"With Surface\" option in the \"Cutout\" node. When you are satisfied, turn it on again. In addition, the volume rendering is very computationally intensive, which is also a major cause of the lag, so you can adjust the parameters in \"Slice Viewer\" mode first, and then do the Cycles rendering when you are satisfied.</p> <p>You may consider using GPU for faster rendering, but please note that Bioxel Nodes only supports Optix GPUs due to its dependency on OSL (Open shader language), and the first time you turn on GPU rendering, you may need to wait for Blender to load the appropriate dependencies (the screen will get stuck), so please be patient.</p> <p>Although the output component looks like a mesh object, it retains its internal information through its volume, so when you cut through the component, you should see an inhomogeneous cross-section made up of volume, rather than just an empty shell like any mesh object. Let's cut the skull to see its complex internal structure.</p>"},{"location":"step_by_step/#cut-and-color","title":"Cut and Color","text":"<p>In the container's geometry nodes panel menu, click Bioxel Nodes &gt; Add a Cutter &gt; Plane Cutter, the addon will insert a \"Cut\" node and a \"Object Cutter\" node. Also, it will create a new plane object named \"Plane Cutter\" to the scene, at this point you should be able to see that the skull has been cut through as expected.</p> <p>Just like the \"Slicer\" object, move and rotate the \"Plane Cutter\" and the position and direction of the cut will change accordingly. Please adjust the Cutter object to a vertical orientation so that it cuts the skull vertically, as shown below.</p> <p></p> <p>The CT value of the skull is inhomogeneous, which reflects the difference in substance density of the bone. We can enhance the display of this difference by coloring. In the Geometry Nodes panel menu of the container, click Add &gt; Bioxel Nodes &gt; Propetry &gt; Set Color by Ramp 5 to add the \"Set Color\" node and connect it after any node. Set the node's parameters \"From Min\" to 0.3 and \"From Max\" to 0.5, as shown below.</p> <p></p> <p>When rendering is turned on, you can clearly see that the calvaria and teeth are colored red, meaning that the bone in these areas is denser. You can try to adjust the parameters of the \"Set Color\" node to recognize their roles. If you feel laggy when draging the parameters, you can temporarily turn off \"With Surface\" and switch to \"Slice Viewer\" mode.</p>"},{"location":"step_by_step/#transformation","title":"Transformation","text":"<p>You may find that the position of the skull is a bit off the origin, this is due to the fact that the addon keeps the position information from the original data record during the import process. If you need to change the position, do not move the container (object) directly as you would in 3D viewport; the addon provides dedicated \"Transform\" node to handle transformations.</p> <p>In the Geometry Nodes panel menu of the container, click Bioxel Nodes &gt; Add a Locator, the addon will insert the \"Transform Parent\" node and create a new empty object named \"Locator\". If you move, rotate, or scale the \"Locator\", the skull will Transform as well. If you also want the origin of the rotational transformation to be set at the geometric center of the skull, just add a \"ReCenter\" node (Add &gt; Bioxel Nodes &gt; Transform &gt; ReCenter) in front of the \"Transform Parent\" node, as shown below.</p> <p></p> <p>Being used to moving objects directly in the 3D viewport, you may find it strange to have an extra step to transform component like this. This is in consideration of the fact that there may be multiple components involved in one container with different transform needs, as well as future development plans for resampling mechanism, which I'll explain in more detail later.</p>"},{"location":"step_by_step/#surface-mesh","title":"Surface Mesh","text":"<p>A mesh, made up of vertexs and faces, is the \"greatest common\" in the 3D world. Therefore, in order to be compatible with other 3D workflow, the addon provides the \"To Surface\" node (Add &gt; Bioxel Nodes &gt; Component &gt; ToSurface), which converts the component into a mesh. Note that the surface mesh is not editable in the container's geometry node, and can only be connected to \"Transform\" and \"Shader\" nodes.</p> <p>As shown below, you can connect \"Slime Shader\" node (Add &gt; Bioxel Nodes &gt; Surface &gt; Slime Shader) after the \"To Surface\" node to give the surface a shader, or connect \"Transform\" nodes.</p> <p></p> <p>If you want to edit the mesh, in the Geometry Nodes panel menu of the container, click Bioxel Nodes &gt; Extract from Container &gt; Extract Mesh, the addon will create a new mesh model object prefixed with the container name, and then you can perform the usual 3D operations, such as digitally sculpting, animating, exporting to 3D print format stl, etc.</p>"},{"location":"step_by_step/#deliver-blender-file","title":"Deliver Blender File","text":"<p>The layers cache is stored in a temporary folder, while the addon's custom nodes are linked to the node library file in addon directory. Both of them are exist locally by default, and if you only deliver the Blender file to other devices, the file will not work properly because the resources are missing.</p> <p>Therefore, you need to save all temporary files before you deliver the Blender file. The procedure is simple:</p> <ol> <li>Save the Blender file.</li> <li>in the top menu, click Bioxel Nodes &gt; Save Node Library, and set the relative path.</li> <li>in the top menu, click Bioxel Nodes &gt; Save All Layers Cache and set the relative path.</li> </ol> <p>Zip the Blender file together with the local node library file and the layer cache files (there may be more than one).</p> <p></p> <p>\ud83e\udd17 If you can follow the documentation up to this point, you're already started!</p>"},{"location":"support_format/","title":"Support Format","text":"<p>Can't wait to play with the addon using your own data? Here's a list of the formats currently supported.</p> Format EXT DICOM .dcm, .DCM, .DICOM, .ima, .IMA BMP .bmp, .BMP JPEG .jpg, .JPG, .jpeg, .JPEG PNG .png, .PNG TIFF .tif, .TIF, .tiff, .TIFF Nifti .nia, .nii, .nii.gz, .hdr, .img, .img.gz Nrrd .nrrd, .nhdr HDF5 .hdf, .h4, .hdf4, .he2, .h5, .hdf5, .he5 OME .ome.tiff, .ome.tif MRC .mrc, .mrc.gz, .map, .map.gz <p>Despite my best efforts, I still can't achieve perfect support for all volumetric data formats, and I will continue to work on this.</p>"},{"location":"support_format/#open-databases","title":"Open Databases","text":"<p>If you don't have volumetric data, then you can download from some open databases.</p> <p>Note that just because they are open and available for download does not mean you can use them for anything! Be sure to look at the description of the available scopes from website.</p> Source Object MorphoSource Open Research Data Dryad Open Research Data Cell Image Library Cells OpenOrganelle Cells Allen Cell Explorer Cells EMDB Protein, Viruses IDC Medical Images Embodi3D Medical Images Github Medical Images NIHR Medical Images Medical Segmentation Decathlon Medical Images Visible Human Project Medical Images"}]}